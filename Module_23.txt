Detection:
Detection refers to the prompt discovery of security events.

 Methods of detection:
 
 Threat Hunter: Threat hunting is the proactive search for threats on a network. Security professionals use threat hunting to 
 uncover malicious activity that was not identified by detection tools and as a way to do further analysis on detections. Threat 
 hunting is also used to detect threats before they cause damage. For example, fileless malware is difficult for detection tools to 
 identify. It’s a form of malware that uses sophisticated evasion techniques such as hiding in memory instead of using files or 
 applications, allowing it to bypass traditional methods of detection like signature analysis. With threat hunting, the combination 
 of active human analysis and technology is used to identify threats like fileless malware. 

 Threat intelligence:
 Organizations can improve their detection capabilities by staying updated on the evolving threat landscape and understanding the 
 relationship between their environment and malicious actors. One way to understand threats is by using threat intelligence, which 
 is evidence-based threat information that provides context about existing or emerging threats. 

 Threat intelligence can come from private or public sources like:

 ->Industry reports: These often include details about attacker's tactics, techniques, and procedures (TTP).

 ->Government advisories: Similar to industry reports, government advisories include details about attackers' TTP. 

 ->Threat data feeds: Threat data feeds provide a stream of threat-related data that can be used to help protect against 
   sophisticated attackers like advanced persistent threats (APTs). APTs are instances when a threat actor maintains unauthorized 
   access to a system for an extended period of time. The data is usually a list of indicators like IP addresses, domains, and file 
   hashes.

 It can be difficult for organizations to efficiently manage large volumes of threat intelligence. Organizations can leverage a 
 threat intelligence platform (TIP) which is an application that collects, centralizes, and analyzes threat intelligence from 
 different sources. TIPs provide a centralized platform for organizations to identify and prioritize relevant threats and improve 
 their security posture. 

 Note: Threat intelligence data feeds are best used to add context to detections. They should not drive detections completely and 
 should be assessed before applied to an organization.

 Cyber deception:
 Cyber deception involves techniques that deliberately deceive malicious actors with the goal of increasing detection and improving 
 defensive strategies. Honeypots are an example of an active cyber defense mechanism that uses deception technology. Honeypots are 
 systems or resources that are created as decoys vulnerable to attacks with the purpose of attracting potential intruders. For 
 example, having a fake file labeled Client Credit Card Information - 2022 can be used to capture the activity of malicious actors 
 by tricking them into accessing the file because it appears to be legitimate. Once a malicious actor tries to access this file, 
 security teams are alerted.
 
Automation for Finding Threats (CI/CD):
CI/CD pipelines help you release software faster, but they can also open up new vulnerabilities for attackers. If someone breaks 
into your pipeline, they could add code, steal private information, or stop your software from working. So, ongoing monitoring that 
automatically finds unusual pipeline activity is critical. Effective CI/CD monitoring uses automation to do more than just collect 
logs. It uses monitoring tools to automatically find unusual things happening in build processes, code, or deployment steps that 
may indicate potential security threats. When these threats are found, security teams can respond quickly and limit the damage. 
This automated threat detection is a main goal of strong CI/CD security.

 Common Indicators of Compromise (IoCs) in CI/CD Pipelines:

 ->Unauthorized Code Changes:

  -->Code changes from people who shouldn't be making changes.

  -->Code changes made at unusual times or from unexpected locations.

  -->Code changes that look suspicious, like confusing code, very large deletions without a good reason, or code that doesn't follow 
     coding rules.

 ->Suspicious Deployment Patterns:

  -->Deployments to unusual or unapproved systems (for example, production deployments started directly from developer branches).

  -->Deployments happening at unexpected times or too often (deployments outside of planned release times).

  -->Deployments started by unusual user accounts or automated accounts that shouldn't be releasing to production.

 ->Compromised Dependencies:

  -->Finding known vulnerabilities (CVEs) in dependencies during automated checks in the CI/CD pipeline.

  -->Suddenly adding new, unexpected dependencies to build settings.

  -->Attempts to download dependencies from unofficial or untrusted sources.

 ->Unusual Pipeline Execution:

  -->Pipeline steps that normally work fine suddenly failing.

  -->Pipelines takeing much longer to run for no clear reason.

  -->Changes in the order or way pipeline steps run without approved changes being made.

 ->Secrets Exposure Attempts:

  -->Logs showing attempts to get to secrets from unapproved places in the pipeline.

  -->Finding private secrets hardcoded in code changes (ideally prevented earlier, but monitoring can catch mistakes).

 Proactive Security Through Monitoring for IoCs:
 Ongoing monitoring of CI/CD pipelines, focusing on automated anomaly detection and finding IoCs, makes your security stronger and 
 more proactive. By using monitoring tools to continuously check pipeline activity for these indicators before serious damage 
 occurs, you can:

 ->Respond to Incidents Quickly: Finding IoCs early helps security teams respond rapidly to potential attacks, stopping problems 
   before attackers reach their goals.

 ->Limit the Damage: Responding quickly based on IoC detection reduces the possible impact of a security issue by limiting how long 
   attackers are in the pipeline.

 ->Improve Threat Knowledge: Checking IoCs gives valuable information about how attackers are targeting your CI/CD, which helps 
   improve security and threat hunting in the future.

 Using Automation to Find Anomalies and IoCs:
 To monitor CI/CD pipelines and automatically find threats, you can use these methods:

  Comprehensive Logging and Auditing:
  Detailed logs are the bases of monitoring. Logs provide the raw data that monitoring tools check for unusual activity and 
  potential Indicators of Compromise (IoCs). The most common logs for finding anomalies include:

  ->Pipeline Execution Logs: To effectively leverage pipeline execution logs for security monitoring, specialized tools employ 
    automated baselining techniques. These tools analyze logs from successful, typical CI/CD pipeline runs to establish a profile 
    of normal operation. This baseline encompasses key performance indicators such as the standard duration of each pipeline stage 
    and expected success and failure rates. By continuously monitoring execution logs and comparing them against this established 
    baseline, the tools can automatically detect anomalous activities. Deviations from the norm, including pipeline steps exceeding 
    typical execution times, unexpected error occurrences, or alterations in the usual step order, are flagged as potential 
    Indicators of Compromise (IoCs), warranting further security scrutiny.

  ->Code Commit Logs: Keep track of code changes for each pipeline run. Unusual code changes, such as changes from people who 
    shouldn't be making changes, changes made late at night, or changes with suspicious content (like very large deletions or 
    confusing code), are important IoCs to monitor.

  ->Access Logs: Monitoring tools can learn who usually accesses CI/CD. Unusual logins, like logins from different countries, failed 
    login attempts followed by a successful login, or login attempts to change important pipeline settings, are strong indicators 
    of compromise.

  ->Deployment Logs: Tools can learn how often deployments usually happen and what those deployments look like. Unusual deployments, 
    such as deployments at odd times or deployments to unexpected places, can be IoCs.

  Security Information and Event Management (SIEM) Integration:
  Connecting your CI/CD logs to a SIEM tool can help  automatically find anomalies at a large scale. SIEM platforms are made to:

  ->Automatically Find Anomalies: SIEMs use machine learning and analytics to automatically find unusual patterns in CI/CD logs, which are  possible IoCs to investigate.

  ->Use Rules to Alert for Known IoCs: You can set up specific rules in the SIEM to find known CI/CD IoCs. For example, rules can send alerts when:

   -->Detection of specific malicious file hashes (related to known CI/CD attacks) are found in build results.

   -->CI/CD servers connect to known malicious command and control (C2) servers (using threat intelligence data).

   -->Someone tries to download or access private secrets outside of approved pipeline steps.

  Real-time Alerting and Notifications:
  Automated alerts make sure security teams are notified right away about unusual activity and possible IoCs, so they can respond 
  quickly. Alerts should be set up for:

  ->Unusual Build Failures: Pipeline steps failing repeatedly, especially after code changes that shouldn't cause failures.

  ->Suspicious Code Changes (Based on Anomalies): Alerts sent by code analysis tools that find highly unusual code changes based on 
    size, author, or confusing content.

  ->Attempts to Expose Secrets: Alerts sent by security tools when someone tries to access or steal secrets from unapproved parts of 
    the pipeline.

  ->Unusual Network Traffic: Alerts for unusual network traffic from CI/CD servers, especially traffic going out to unknown or 
    suspicious locations.

  Performance Monitoring to Find IoAs and Discover IoCs:
  Performance monitoring, while mainly used to make sure things are running smoothly, can also indirectly help find IoCs. 
  Performance issues (Indicators of Attack - IoAs) like sudden slowdowns or CI/CD servers running out of resources can lead to 
  deeper checks that may uncover IoCs.

  Continuous Vulnerability Scanning:
  Regularly checking the CI/CD infrastructure for weaknesses can proactively find vulnerable parts. This includes Common 
  Vulnerabilities and Exposures (CVEs) in CI/CD tools, plugins, and containers. These weaknesses are potential IoCs. They highlight 
  areas that need to be patched right away to prevent attacks and possible pipeline compromise.

Indicators of compromise:
Indicators of compromise (IoCs) are observable evidence that suggests signs of a potential security incident. IoCs chart specific 
pieces of evidence that are associated with an attack, like a file name associated with a type of malware. You can think of an IoC 
as evidence that points to something that's already happened, like noticing that a valuable has been stolen from inside of a car. 

Indicators of attack (IoA) are the series of observed events that indicate a real-time incident.  IoAs focus on identifying the 
behavioral evidence of an attacker, including their methods and intentions.

Essentially, IoCs help to identify the who and what of an attack after it's taken place, while IoAs focus on finding the why and 
how of an ongoing or unknown attack. For example, observing a process that makes a network connection is an example of an IoA. The 
filename of the process and the IP address that the process contacted are examples of the related IoCs.

Note: Indicators of compromise are not always a confirmation that a security incident has happened. IoCs may be the result of human 
error, system malfunctions, and other reasons not related to security. 

 Pyramid of Pain:
 Not all indicators of compromise are equal in the value they provide to security teams. It’s important for security professionals 
 to understand the different types of indicators of compromise so that they can quickly and effectively detect and respond to them. 
 This is why security researcher David J. Bianco created the concept of the Pyramid of Pain, with the goal of improving how 
 indicators of compromise are used in incident detection.

 The Pyramid of Pain captures the relationship between indicators of compromise and the level of difficulty that malicious actors 
 experience when indicators of compromise are blocked by security teams. It lists the different types of indicators of compromise 
 that security professionals use to identify malicious activity. 

 Each type of indicator of compromise is separated into levels of difficulty. These levels represent the “pain” levels that an 
 attacker faces when security teams block the activity associated with the indicator of compromise. For example, blocking an IP 
 address associated with a malicious actor is labeled as easy because malicious actors can easily use different IP addresses to 
 work around this and continue with their malicious efforts. If security teams are able to block the IoCs located at the top of the 
 pyramid, the more difficult it becomes for attackers to continue their attacks. Here’s a breakdown of the different types of 
 indicators of compromise found in the Pyramid of Pain. 

 1.Hash values: Hashes that correspond to known malicious files. These are often used to provide unique references to specific 
   samples of malware or to files involved in an intrusion.

 2.IP addresses: An internet protocol address like 192.168.1.1

 3.Domain names: A web address such as www.google.com 

 3.Network artifacts: Observable evidence created by malicious actors on a network. For example, information found in network 
   protocols such as User-Agent strings. 

 4.Host artifacts: Observable evidence created by malicious actors on a host. A host is any device that’s connected on a network. 
   For example, the name of a file created by malware.

 5.Tools: Software that’s used by a malicious actor to achieve their goal. For example, attackers can use password cracking tools 
   like John the Ripper to perform password attacks to gain access into an account.

 6.Tactics, techniques, and procedures (TTPs): This is the behavior of a malicious actor. Tactics refer to the high-level overview 
   of the behavior. Techniques provide detailed descriptions of the behavior relating to the tactic. Procedures are highly detailed 
   descriptions of the technique. TTPs are the hardest to detect.

Benefits of Documentation:

->Transparency

->Standardization

->Clarity
  